Args in experiment:
Namespace(activation='gelu', alpha=0.2, attn_dropout=0.1, batch_size=16, ca_layers=2, checkpoints='./checkpoints/', d_ff=512, d_model=512, data='custom', data_path='electricity.csv', des='Exp', devices='0,1,2,3', dropout=0.0, embed='timeF', embedding_epochs=5, embedding_lr=0.0005, enc_in=321, features='M', freq='h', gpu=0, ia_layers=1, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type1', model='TimeBridge', model_id='electricity_720_96', n_heads=32, num_p=4, num_workers=10, output_attention=False, patience=3, pct_start=0.2, pd_layers=1, period=24, pred_len=96, revin=True, root_path='./data/electricity/', seasonal_patterns='Monthly', seq_len=720, stable_len=4, target='OT', train_epochs=10, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : electricity_720_96_TimeBridge_custom_bs16_ftM_sl720_ll48_pl96_dm512_nh32_ial1_pdl1_cal2_df512_ebtimeF_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17597
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.7254777
	speed: 0.4693s/iter; left time: 5111.4583s
	iters: 200, epoch: 1 | loss: 0.7229465
	speed: 0.4683s/iter; left time: 5052.9553s
	iters: 300, epoch: 1 | loss: 0.6489978
	speed: 0.4430s/iter; left time: 4736.0139s
	iters: 400, epoch: 1 | loss: 0.6932676
	speed: 0.4429s/iter; left time: 4690.4479s
	iters: 500, epoch: 1 | loss: 0.6049957
	speed: 0.4419s/iter; left time: 4635.6116s
	iters: 600, epoch: 1 | loss: 0.5784625
	speed: 0.4413s/iter; left time: 4585.8036s
	iters: 700, epoch: 1 | loss: 0.6669153
	speed: 0.4721s/iter; left time: 4857.9109s
	iters: 800, epoch: 1 | loss: 0.5889518
	speed: 0.4993s/iter; left time: 5087.9625s
	iters: 900, epoch: 1 | loss: 0.5929949
	speed: 0.4931s/iter; left time: 4976.2559s
	iters: 1000, epoch: 1 | loss: 0.5928901
	speed: 0.4418s/iter; left time: 4413.6076s
Epoch: 1 cost time: 504.62672781944275
Epoch: 1, Steps: 1099 | Train Loss: 0.6536466 Vali Loss: 0.1116551 Test Loss: 0.1341862
Validation loss decreased (inf --> 0.111655).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.5593156
	speed: 3.6926s/iter; left time: 36157.8467s
	iters: 200, epoch: 2 | loss: 0.6083964
	speed: 0.4411s/iter; left time: 4274.6982s
	iters: 300, epoch: 2 | loss: 0.6255813
	speed: 0.4606s/iter; left time: 4418.1505s
	iters: 400, epoch: 2 | loss: 0.6061805
	speed: 0.4553s/iter; left time: 4321.8750s
	iters: 500, epoch: 2 | loss: 0.5690150
	speed: 0.4797s/iter; left time: 4505.1303s
	iters: 600, epoch: 2 | loss: 0.5598524
	speed: 0.5116s/iter; left time: 4753.9062s
	iters: 700, epoch: 2 | loss: 0.5646215
	speed: 0.4414s/iter; left time: 4057.6420s
	iters: 800, epoch: 2 | loss: 0.5713332
	speed: 0.4658s/iter; left time: 4234.6594s
	iters: 900, epoch: 2 | loss: 0.5728896
	speed: 0.4475s/iter; left time: 4024.1601s
	iters: 1000, epoch: 2 | loss: 0.5594318
	speed: 0.4841s/iter; left time: 4304.8644s
Epoch: 2 cost time: 521.6137516498566
Epoch: 2, Steps: 1099 | Train Loss: 0.5925030 Vali Loss: 0.1095943 Test Loss: 0.1315657
Validation loss decreased (0.111655 --> 0.109594).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.5558483
	speed: 3.6324s/iter; left time: 31576.7823s
	iters: 200, epoch: 3 | loss: 0.5676796
	speed: 0.5025s/iter; left time: 4317.8576s
	iters: 300, epoch: 3 | loss: 0.5710020
	speed: 0.4922s/iter; left time: 4180.1323s
	iters: 400, epoch: 3 | loss: 0.5386259
	speed: 0.4417s/iter; left time: 3707.1158s
	iters: 500, epoch: 3 | loss: 0.5341497
	speed: 0.4705s/iter; left time: 3902.2371s
	iters: 600, epoch: 3 | loss: 0.5985558
	speed: 0.4435s/iter; left time: 3633.5346s
	iters: 700, epoch: 3 | loss: 0.5810356
	speed: 0.4421s/iter; left time: 3577.8636s
	iters: 800, epoch: 3 | loss: 0.5758532
	speed: 0.4412s/iter; left time: 3526.4952s
	iters: 900, epoch: 3 | loss: 0.5811830
	speed: 0.4509s/iter; left time: 3558.8442s
	iters: 1000, epoch: 3 | loss: 0.5770687
	speed: 0.4635s/iter; left time: 3612.1334s
Epoch: 3 cost time: 512.0445010662079
Epoch: 3, Steps: 1099 | Train Loss: 0.5691798 Vali Loss: 0.1064411 Test Loss: 0.1289090
Validation loss decreased (0.109594 --> 0.106441).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.5390489
	speed: 3.5420s/iter; left time: 26897.8218s
	iters: 200, epoch: 4 | loss: 0.5310108
	speed: 0.4412s/iter; left time: 3306.1419s
	iters: 300, epoch: 4 | loss: 0.5523210
	speed: 0.5252s/iter; left time: 3883.5782s
	iters: 400, epoch: 4 | loss: 0.5640725
	speed: 0.4783s/iter; left time: 3488.7474s
	iters: 500, epoch: 4 | loss: 0.5373438
	speed: 0.4689s/iter; left time: 3373.2787s
	iters: 600, epoch: 4 | loss: 0.5403600
	speed: 0.4440s/iter; left time: 3150.0659s
	iters: 700, epoch: 4 | loss: 0.5796392
	speed: 0.4526s/iter; left time: 3165.1373s
	iters: 800, epoch: 4 | loss: 0.5376197
	speed: 0.5337s/iter; left time: 3679.2102s
	iters: 900, epoch: 4 | loss: 0.5506208
	speed: 0.4560s/iter; left time: 3098.3832s
	iters: 1000, epoch: 4 | loss: 0.5486529
	speed: 0.4739s/iter; left time: 3172.0956s
Epoch: 4 cost time: 515.7568237781525
Epoch: 4, Steps: 1099 | Train Loss: 0.5527385 Vali Loss: 0.1052574 Test Loss: 0.1271325
Validation loss decreased (0.106441 --> 0.105257).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.5362111
	speed: 3.5664s/iter; left time: 23163.6806s
	iters: 200, epoch: 5 | loss: 0.5417425
	speed: 0.4573s/iter; left time: 2924.3922s
	iters: 300, epoch: 5 | loss: 0.5336940
	speed: 0.4421s/iter; left time: 2782.8792s
	iters: 400, epoch: 5 | loss: 0.5239987
	speed: 0.4426s/iter; left time: 2742.1327s
	iters: 500, epoch: 5 | loss: 0.5142578
	speed: 0.4964s/iter; left time: 3025.5750s
	iters: 600, epoch: 5 | loss: 0.5137376
	speed: 0.5068s/iter; left time: 3038.0514s
	iters: 700, epoch: 5 | loss: 0.5683806
	speed: 0.4582s/iter; left time: 2701.2824s
	iters: 800, epoch: 5 | loss: 0.5587450
	speed: 0.4427s/iter; left time: 2565.2807s
	iters: 900, epoch: 5 | loss: 0.5094597
	speed: 0.4421s/iter; left time: 2517.9182s
	iters: 1000, epoch: 5 | loss: 0.5759045
	speed: 0.5066s/iter; left time: 2834.5088s
Epoch: 5 cost time: 520.6241939067841
Epoch: 5, Steps: 1099 | Train Loss: 0.5418762 Vali Loss: 0.1046246 Test Loss: 0.1275322
Validation loss decreased (0.105257 --> 0.104625).  Saving model ...
	iters: 100, epoch: 6 | loss: 0.5158641
	speed: 3.0779s/iter; left time: 16608.1102s
	iters: 200, epoch: 6 | loss: 0.5334522
	speed: 0.4141s/iter; left time: 2192.8568s
	iters: 300, epoch: 6 | loss: 0.5283599
	speed: 0.4148s/iter; left time: 2155.3694s
	iters: 400, epoch: 6 | loss: 0.5481692
	speed: 0.4313s/iter; left time: 2198.1232s
	iters: 500, epoch: 6 | loss: 0.5731501
	speed: 0.4136s/iter; left time: 2066.1881s
	iters: 600, epoch: 6 | loss: 0.4972918
	speed: 0.4158s/iter; left time: 2035.8937s
	iters: 700, epoch: 6 | loss: 0.5399220
	speed: 0.4156s/iter; left time: 1993.2082s
	iters: 800, epoch: 6 | loss: 0.5352869
	speed: 0.4185s/iter; left time: 1965.3878s
	iters: 900, epoch: 6 | loss: 0.5171489
	speed: 0.4245s/iter; left time: 1950.9246s
	iters: 1000, epoch: 6 | loss: 0.5112534
	speed: 0.4162s/iter; left time: 1871.2024s
